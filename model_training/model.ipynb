{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will be the model in itself, in it we will split the data, pre-process it and then use a model to predict prices in the test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1648,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1649,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first step is that we have to split the data correctly\n",
    "df_final = pd.read_csv('ready_to_learn_csv.csv')\n",
    "y = df_final['Price'] \n",
    "X = df_final.drop(['Price'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)#, random_state=0)#random state, if given it will be always the same split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1650,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encoding():\n",
    "    \"\"\"\n",
    "    change the categorical value with the ordinal encoding method\n",
    "    \"\"\"\n",
    "    global X_train\n",
    "    global X_test\n",
    "    \n",
    "    X_train = X_train.replace({\"Furnished\": {False: 0, True: 1}})\n",
    "    X_train = X_train.replace({\"Open_fire\": {False: 0, True: 1}})\n",
    "    X_train = X_train.replace({\"Swimming_pool\": {False: 0, True: 1}})\n",
    "    X_train = X_train.replace({\"State_of_the_building\":{\"AS_NEW\": 6, \"JUST_RENOVATED\": 5, \"GOOD\": 4, \"TO_BE_DONE_UP\": 3, \"TO_RENOVATE\": 2, \"TO_RESTORE\": 1}})#check meaning of these\n",
    "    X_test = X_test.replace({\"Furnished\": {False: 0, True: 1}})\n",
    "    X_test = X_test.replace({\"Open_fire\": {False: 0, True: 1}})\n",
    "    X_test = X_test.replace({\"Swimming_pool\": {False: 0, True: 1}})\n",
    "    X_test = X_test.replace({\"State_of_the_building\":{\"AS_NEW\": 6, \"JUST_RENOVATED\": 5, \"GOOD\": 4, \"TO_BE_DONE_UP\": 3, \"TO_RENOVATE\": 2, \"TO_RESTORE\": 1}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1651,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_price_per_sm():\n",
    "    \"\"\"\n",
    "    For each localities in the X_train part, this function will compute the median price per square meter, \n",
    "    then it will merge these values with X_train and X_test and will delete the collumn locality\n",
    "    \"\"\"\n",
    "    global X_train\n",
    "    global X_test\n",
    "\n",
    "    #creation of a new dataframe, containing locality and median price per square meter of the locality (on X_train)\n",
    "    area = X_train[\"Living_Area\"]+ df_final[\"Terrace_Area\"] + df_final[\"Garden_Area\"]\n",
    "    X_train[\"Price_Squared_Meter\"] = df_final[\"Price\"] / area\n",
    "    median_price_meter = X_train.groupby(\"Locality\")[\"Price_Squared_Meter\"].median()\n",
    "    del X_train[\"Price_Squared_Meter\"]\n",
    "\n",
    "    #merge this new df with x_train and x_test\n",
    "    X_train = X_train.merge(median_price_meter, how='left', on='Locality')\n",
    "    X_test = X_test.merge(median_price_meter, how='left', on='Locality')\n",
    "\n",
    "    #delete Locality collumn\n",
    "    del X_train['Locality']\n",
    "    del X_test['Locality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1652,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values():\n",
    "    \"\"\"\n",
    "    this function will deal with missing values, for the needed columns it adds a new column_wasmissing, \n",
    "    and 'replace' the missing values with the help of a simple imputer\n",
    "    \"\"\"\n",
    "    global X_train\n",
    "    global X_test\n",
    "    cols_with_missing = ['Number_of_facades', 'Furnished', 'Swimming_pool', 'State_of_the_building', 'Price_Squared_Meter'] #type of properties, 'Number_of_rooms', 'Open_fire', Price_Squared_Meter\n",
    "    for col in cols_with_missing:\n",
    "        X_train[col + '_was_missing'] = X_train[col].isnull()+0.0000001\n",
    "        X_test[col + '_was_missing'] = X_test[col].isnull()+0.0000001\n",
    "    \n",
    "    my_imputer = SimpleImputer()\n",
    "    imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "    imputed_X_test = pd.DataFrame(my_imputer.fit_transform(X_test))\n",
    "    # Imputation removed column names; put them back\n",
    "    imputed_X_train.columns = X_train.columns \n",
    "    imputed_X_test.columns = X_test.columns \n",
    "\n",
    "    X_train = imputed_X_train\n",
    "    X_test = imputed_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1653,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize():\n",
    "    \"\"\"\n",
    "    This function standardize each columns\n",
    "    \"\"\"\n",
    "    global X_train\n",
    "    global X_test\n",
    "    for column in X_train.columns :\n",
    "        # Get mean and standard deviation from training set (per feature)\n",
    "        mean = np.mean(X_train[column])\n",
    "        stdev = np.std(X_train[column])\n",
    "\n",
    "        # Standardize training and testing set using the mean and standard deviation from the training set\n",
    "        X_train[column] = (X_train[column] - mean) / stdev\n",
    "        X_test[column] = (X_test[column] - mean) / stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1654,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    \"\"\"\n",
    "    this function will preprocess the data, it deals with nan values, non numerical values and normalize the columns\n",
    "    \"\"\"\n",
    "    global X_train\n",
    "    global X_test\n",
    "\n",
    "    #deal with categorical variables----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    #one hot encoding\n",
    "    X_train = pd.get_dummies(X_train, columns=[\"Type_of_property\"], drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, columns=[\"Type_of_property\"], drop_first=True)\n",
    "\n",
    "    #ordinal encoding\n",
    "    ordinal_encoding()\n",
    "\n",
    "    #locality is an int but we consider it as a categorical variabe, we will replace this column by the median price per square meter for each different localities\n",
    "    get_median_price_per_sm()\n",
    "\n",
    "    #deal with missing values---------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    missing_values()\n",
    "\n",
    "    #standardize----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    standardize()\n",
    "\n",
    "    #resampling-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    #todo\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1655,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "#X_test.to_csv('test.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1656,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error 119596.98747422134\n",
      "Evaluating the model on the training set yields an accuracy of 94.83505477253289%\n",
      "Evaluating the model on the testing set yields an accuracy of 78.56%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=0, n_estimators=300, max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(\"mean absolute error\", mean_absolute_error(y_test, preds))\n",
    "\n",
    "score = model.score(X_train, y_train)\n",
    "print(\"Evaluating the model on the training set yields an accuracy of {}%\".format(score*100))\n",
    "score=model.score(X_test, y_test)\n",
    "print(\"Evaluating the model on the testing set yields an accuracy of {:.2f}%\".format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error 131312.35442463966\n",
      "Evaluating the model on the training set yields an accuracy of 93.32448474493188%\n",
      "Evaluating the model on the testing set yields an accuracy of 73.74%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=5, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(\"mean absolute error\", mean_absolute_error(y_test, preds))\n",
    "\n",
    "#r-squared error\n",
    "score = model.score(X_train, y_train)\n",
    "print(\"Evaluating the model on the training set yields an accuracy of {}%\".format(score*100))\n",
    "score=model.score(X_test, y_test)\n",
    "print(\"Evaluating the model on the testing set yields an accuracy of {:.2f}%\".format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.neighbors import KNeighborsRegressor\\n\\nmodel = KNeighborsRegressor(n_neighbors=5)\\nmodel.fit(X_train, y_train)\\npreds = model.predict(X_test)\\nprint(\"mean absolute error\", mean_absolute_error(y_test, preds))\\n\\nscore = model.score(X_train, y_train)\\nprint(\"Evaluating the model on the training set yields an accuracy of {}%\".format(score*100))\\nscore=model.score(X_test, y_test)\\nprint(\"Evaluating the model on the testing set yields an accuracy of {:.2f}%\".format(score*100))\\n'"
      ]
     },
     "execution_count": 1658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(\"mean absolute error\", mean_absolute_error(y_test, preds))\n",
    "\n",
    "score = model.score(X_train, y_train)\n",
    "print(\"Evaluating the model on the training set yields an accuracy of {}%\".format(score*100))\n",
    "score=model.score(X_test, y_test)\n",
    "print(\"Evaluating the model on the testing set yields an accuracy of {:.2f}%\".format(score*100))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble import AdaBoostRegressor\\n\\nmodel = AdaBoostRegressor(random_state=0, n_estimators=3)\\nmodel.fit(X_train, y_train)\\npreds = model.predict(X_test)\\nprint(\"mean absolute error\", mean_absolute_error(y_test, preds))\\n\\nscore = model.score(X_train, y_train)\\nprint(\"Evaluating the model on the training set yields an accuracy of {}%\".format(score*100))\\nscore=model.score(X_test, y_test)\\nprint(\"Evaluating the model on the testing set yields an accuracy of {:.2f}%\".format(score*100))\\n'"
      ]
     },
     "execution_count": 1659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "model = AdaBoostRegressor(random_state=0, n_estimators=3)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(\"mean absolute error\", mean_absolute_error(y_test, preds))\n",
    "\n",
    "score = model.score(X_train, y_train)\n",
    "print(\"Evaluating the model on the training set yields an accuracy of {}%\".format(score*100))\n",
    "score=model.score(X_test, y_test)\n",
    "print(\"Evaluating the model on the testing set yields an accuracy of {:.2f}%\".format(score*100))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.tree import DecisionTreeRegressor\\n\\nmodel = DecisionTreeRegressor(random_state=2)\\nmodel.fit(X_train, y_train)\\npreds = model.predict(X_test)\\nprint(\"mean absolute error\", mean_absolute_error(y_test, preds))\\n\\nscore = model.score(X_train, y_train)\\nprint(\"Evaluating the model on the training set yields an accuracy of {}%\".format(score*100))\\nscore=model.score(X_test, y_test)\\nprint(\"Evaluating the model on the testing set yields an accuracy of {:.2f}%\".format(score*100))\\n'"
      ]
     },
     "execution_count": 1660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=2)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "print(\"mean absolute error\", mean_absolute_error(y_test, preds))\n",
    "\n",
    "score = model.score(X_train, y_train)\n",
    "print(\"Evaluating the model on the training set yields an accuracy of {}%\".format(score*100))\n",
    "score=model.score(X_test, y_test)\n",
    "print(\"Evaluating the model on the testing set yields an accuracy of {:.2f}%\".format(score*100))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.preprocessing import PolynomialFeatures\\nfrom sklearn.linear_model import LinearRegression\\n\\npoly = PolynomialFeatures(degree=2)\\nX_train_poly = poly.fit_transform(X_train)\\nX_test_poly = poly.transform(X_test)\\n\\nmodel = LinearRegression()\\nmodel.fit(X_train_poly, y_train)\\n\\npreds = model.predict(X_test_poly)\\nprint(\"mean absolute error\", mean_absolute_error(y_test, preds))\\n\\nscore = model.score(X_train_poly, y_train)\\nprint(\"Evaluating the model on the training set yields an accuracy of {}%\".format(score*100))\\nscore=model.score(X_test_poly, y_test)\\nprint(\"Evaluating the model on the testing set yields an accuracy of {:.2f}%\".format(score*100))\\n'"
      ]
     },
     "execution_count": 1661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "preds = model.predict(X_test_poly)\n",
    "print(\"mean absolute error\", mean_absolute_error(y_test, preds))\n",
    "\n",
    "score = model.score(X_train_poly, y_train)\n",
    "print(\"Evaluating the model on the training set yields an accuracy of {}%\".format(score*100))\n",
    "score=model.score(X_test_poly, y_test)\n",
    "print(\"Evaluating the model on the testing set yields an accuracy of {:.2f}%\".format(score*100))\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking to the previous test we will investigate to optimise GradientBoostingRegressor and the random forest one (they are the 2 more promosing). We can see that the others get bad results, decisiontreeregressor seems to overfit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BeCode_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "527d3136a15c09fb94e6304e1a4ef36802614441d5a4ed619fba2891eaa8d1fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
